===============================================================================

Train file         = splits/train_5.7k_cropped_remapped_siamese.txt
Val file           = splits/val_5.7k_cropped_remapped.txt
Run No             = 39
Model save folder  = models/run_39
-------------------------------
Optimisation Parameters
-------------------------------
lr                 = 0.00050
epochs             = 100
Batch size         = 48
Test Batch size    = 16
Using device: cuda
THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=405 error=11 : invalid argument
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 192, 192]          15,616
              ReLU-2         [-1, 64, 192, 192]               0
         MaxPool2d-3           [-1, 64, 96, 96]               0
       BatchNorm2d-4           [-1, 64, 96, 96]             128
            Conv2d-5           [-1, 64, 96, 96]          36,928
              ReLU-6           [-1, 64, 96, 96]               0
       BatchNorm2d-7           [-1, 64, 96, 96]             128
            Conv2d-8           [-1, 64, 96, 96]          36,928
              ReLU-9           [-1, 64, 96, 96]               0
        MaxPool2d-10           [-1, 64, 48, 48]               0
      BatchNorm2d-11           [-1, 64, 48, 48]             128
           Conv2d-12          [-1, 128, 48, 48]           8,320
      BatchNorm2d-13          [-1, 128, 48, 48]             256
           Conv2d-14           [-1, 64, 48, 48]           8,256
             ReLU-15           [-1, 64, 48, 48]               0
      BatchNorm2d-16           [-1, 64, 48, 48]             128
           Conv2d-17           [-1, 64, 48, 48]          36,928
             ReLU-18           [-1, 64, 48, 48]               0                                                                            [491/1961]
      BatchNorm2d-19           [-1, 64, 48, 48]             128
           Conv2d-20          [-1, 128, 48, 48]           8,320
             ReLU-21          [-1, 128, 48, 48]               0
      BatchNorm2d-22          [-1, 128, 48, 48]             256
           Conv2d-23           [-1, 64, 48, 48]           8,256
             ReLU-24           [-1, 64, 48, 48]               0
      BatchNorm2d-25           [-1, 64, 48, 48]             128
           Conv2d-26           [-1, 64, 48, 48]          36,928
             ReLU-27           [-1, 64, 48, 48]               0
      BatchNorm2d-28           [-1, 64, 48, 48]             128
           Conv2d-29          [-1, 128, 48, 48]           8,320
             ReLU-30          [-1, 128, 48, 48]               0
      BatchNorm2d-31          [-1, 128, 48, 48]             256
           Conv2d-32           [-1, 64, 48, 48]           8,256
             ReLU-33           [-1, 64, 48, 48]               0
      BatchNorm2d-34           [-1, 64, 48, 48]             128
           Conv2d-35           [-1, 64, 48, 48]          36,928
             ReLU-36           [-1, 64, 48, 48]               0
      BatchNorm2d-37           [-1, 64, 48, 48]             128
           Conv2d-38          [-1, 128, 48, 48]           8,320
             ReLU-39          [-1, 128, 48, 48]               0
      BatchNorm2d-40          [-1, 128, 48, 48]             256
           Conv2d-41           [-1, 64, 48, 48]           8,256
             ReLU-42           [-1, 64, 48, 48]               0
      BatchNorm2d-43           [-1, 64, 48, 48]             128
           Conv2d-44           [-1, 64, 48, 48]          36,928
             ReLU-45           [-1, 64, 48, 48]               0
      BatchNorm2d-46           [-1, 64, 48, 48]             128
           Conv2d-47          [-1, 128, 48, 48]           8,320
             ReLU-48          [-1, 128, 48, 48]               0
        MaxPool2d-49          [-1, 128, 24, 24]               0
      BatchNorm2d-50          [-1, 128, 24, 24]             256
           Conv2d-51          [-1, 256, 24, 24]          33,024
      BatchNorm2d-52          [-1, 256, 24, 24]             512
           Conv2d-53           [-1, 64, 24, 24]          16,448
             ReLU-54           [-1, 64, 24, 24]               0                                                                            [455/1961]
      BatchNorm2d-55           [-1, 64, 24, 24]             128
           Conv2d-56           [-1, 64, 24, 24]          36,928
             ReLU-57           [-1, 64, 24, 24]               0
      BatchNorm2d-58           [-1, 64, 24, 24]             128
           Conv2d-59          [-1, 256, 24, 24]          16,640
             ReLU-60          [-1, 256, 24, 24]               0
      BatchNorm2d-61          [-1, 256, 24, 24]             512
           Conv2d-62           [-1, 64, 24, 24]          16,448
             ReLU-63           [-1, 64, 24, 24]               0
      BatchNorm2d-64           [-1, 64, 24, 24]             128
           Conv2d-65           [-1, 64, 24, 24]          36,928
             ReLU-66           [-1, 64, 24, 24]               0
      BatchNorm2d-67           [-1, 64, 24, 24]             128
           Conv2d-68          [-1, 256, 24, 24]          16,640
             ReLU-69          [-1, 256, 24, 24]               0
      BatchNorm2d-70          [-1, 256, 24, 24]             512
           Conv2d-71           [-1, 64, 24, 24]          16,448
             ReLU-72           [-1, 64, 24, 24]               0
      BatchNorm2d-73           [-1, 64, 24, 24]             128
           Conv2d-74           [-1, 64, 24, 24]          36,928
             ReLU-75           [-1, 64, 24, 24]               0
      BatchNorm2d-76           [-1, 64, 24, 24]             128
           Conv2d-77          [-1, 256, 24, 24]          16,640
             ReLU-78          [-1, 256, 24, 24]               0
      BatchNorm2d-79          [-1, 256, 24, 24]             512
           Conv2d-80           [-1, 64, 24, 24]          16,448
             ReLU-81           [-1, 64, 24, 24]               0
      BatchNorm2d-82           [-1, 64, 24, 24]             128
           Conv2d-83           [-1, 64, 24, 24]          36,928
             ReLU-84           [-1, 64, 24, 24]               0
      BatchNorm2d-85           [-1, 64, 24, 24]             128
           Conv2d-86          [-1, 256, 24, 24]          16,640
             ReLU-87          [-1, 256, 24, 24]               0
        MaxPool2d-88          [-1, 256, 12, 12]               0
      BatchNorm2d-89          [-1, 256, 12, 12]             512
           Conv2d-90          [-1, 384, 12, 12]          98,688                                                                            [419/1961]
      BatchNorm2d-91          [-1, 384, 12, 12]             768
           Conv2d-92           [-1, 96, 12, 12]          36,960
             ReLU-93           [-1, 96, 12, 12]               0
      BatchNorm2d-94           [-1, 96, 12, 12]             192
           Conv2d-95           [-1, 96, 12, 12]          83,040
             ReLU-96           [-1, 96, 12, 12]               0
      BatchNorm2d-97           [-1, 96, 12, 12]             192
           Conv2d-98          [-1, 384, 12, 12]          37,248
             ReLU-99          [-1, 384, 12, 12]               0
     BatchNorm2d-100          [-1, 384, 12, 12]             768
          Conv2d-101           [-1, 96, 12, 12]          36,960
            ReLU-102           [-1, 96, 12, 12]               0
     BatchNorm2d-103           [-1, 96, 12, 12]             192
          Conv2d-104           [-1, 96, 12, 12]          83,040
            ReLU-105           [-1, 96, 12, 12]               0
     BatchNorm2d-106           [-1, 96, 12, 12]             192
          Conv2d-107          [-1, 384, 12, 12]          37,248
            ReLU-108          [-1, 384, 12, 12]               0
     BatchNorm2d-109          [-1, 384, 12, 12]             768
          Conv2d-110           [-1, 96, 12, 12]          36,960
            ReLU-111           [-1, 96, 12, 12]               0
     BatchNorm2d-112           [-1, 96, 12, 12]             192
          Conv2d-113           [-1, 96, 12, 12]          83,040
            ReLU-114           [-1, 96, 12, 12]               0
     BatchNorm2d-115           [-1, 96, 12, 12]             192
          Conv2d-116          [-1, 384, 12, 12]          37,248
            ReLU-117          [-1, 384, 12, 12]               0
     BatchNorm2d-118          [-1, 384, 12, 12]             768
          Conv2d-119           [-1, 96, 12, 12]          36,960
            ReLU-120           [-1, 96, 12, 12]               0
     BatchNorm2d-121           [-1, 96, 12, 12]             192
          Conv2d-122           [-1, 96, 12, 12]          83,040
            ReLU-123           [-1, 96, 12, 12]               0
     BatchNorm2d-124           [-1, 96, 12, 12]             192
          Conv2d-125          [-1, 384, 12, 12]          37,248
            ReLU-126          [-1, 384, 12, 12]               0                                                                            [383/1961]
       MaxPool2d-127            [-1, 384, 6, 6]               0
     BatchNorm2d-128            [-1, 384, 6, 6]             768
          Conv2d-129            [-1, 512, 6, 6]         197,120
     BatchNorm2d-130            [-1, 512, 6, 6]           1,024
          Conv2d-131            [-1, 128, 6, 6]          65,664
            ReLU-132            [-1, 128, 6, 6]               0
     BatchNorm2d-133            [-1, 128, 6, 6]             256
          Conv2d-134            [-1, 128, 6, 6]         147,584
            ReLU-135            [-1, 128, 6, 6]               0
     BatchNorm2d-136            [-1, 128, 6, 6]             256
          Conv2d-137            [-1, 512, 6, 6]          66,048
            ReLU-138            [-1, 512, 6, 6]               0
     BatchNorm2d-139            [-1, 512, 6, 6]           1,024
          Conv2d-140            [-1, 128, 6, 6]          65,664
            ReLU-141            [-1, 128, 6, 6]               0
     BatchNorm2d-142            [-1, 128, 6, 6]             256
          Conv2d-143            [-1, 128, 6, 6]         147,584
            ReLU-144            [-1, 128, 6, 6]               0
     BatchNorm2d-145            [-1, 128, 6, 6]             256
          Conv2d-146            [-1, 512, 6, 6]          66,048
            ReLU-147            [-1, 512, 6, 6]               0
     BatchNorm2d-148            [-1, 512, 6, 6]           1,024
          Conv2d-149            [-1, 128, 6, 6]          65,664
            ReLU-150            [-1, 128, 6, 6]               0
     BatchNorm2d-151            [-1, 128, 6, 6]             256
          Conv2d-152            [-1, 128, 6, 6]         147,584
            ReLU-153            [-1, 128, 6, 6]               0
     BatchNorm2d-154            [-1, 128, 6, 6]             256
          Conv2d-155            [-1, 512, 6, 6]          66,048
            ReLU-156            [-1, 512, 6, 6]               0
     BatchNorm2d-157            [-1, 512, 6, 6]           1,024
          Conv2d-158            [-1, 128, 6, 6]          65,664
            ReLU-159            [-1, 128, 6, 6]               0
     BatchNorm2d-160            [-1, 128, 6, 6]             256
          Conv2d-161            [-1, 128, 6, 6]         147,584
            ReLU-162            [-1, 128, 6, 6]               0                                                                            [347/1961]
     BatchNorm2d-163            [-1, 128, 6, 6]             256
          Conv2d-164            [-1, 512, 6, 6]          66,048
            ReLU-165            [-1, 512, 6, 6]               0
       MaxPool2d-166            [-1, 512, 1, 1]               0
          Conv2d-167         [-1, 64, 192, 192]          15,616
            ReLU-168         [-1, 64, 192, 192]               0
       MaxPool2d-169           [-1, 64, 96, 96]               0
     BatchNorm2d-170           [-1, 64, 96, 96]             128
          Conv2d-171           [-1, 64, 96, 96]          36,928
            ReLU-172           [-1, 64, 96, 96]               0
     BatchNorm2d-173           [-1, 64, 96, 96]             128
          Conv2d-174           [-1, 64, 96, 96]          36,928
            ReLU-175           [-1, 64, 96, 96]               0
       MaxPool2d-176           [-1, 64, 48, 48]               0
     BatchNorm2d-177           [-1, 64, 48, 48]             128
          Conv2d-178          [-1, 128, 48, 48]           8,320
     BatchNorm2d-179          [-1, 128, 48, 48]             256
          Conv2d-180           [-1, 64, 48, 48]           8,256
            ReLU-181           [-1, 64, 48, 48]               0
     BatchNorm2d-182           [-1, 64, 48, 48]             128
          Conv2d-183           [-1, 64, 48, 48]          36,928
            ReLU-184           [-1, 64, 48, 48]               0
     BatchNorm2d-185           [-1, 64, 48, 48]             128
          Conv2d-186          [-1, 128, 48, 48]           8,320
            ReLU-187          [-1, 128, 48, 48]               0
     BatchNorm2d-188          [-1, 128, 48, 48]             256
          Conv2d-189           [-1, 64, 48, 48]           8,256
            ReLU-190           [-1, 64, 48, 48]               0
     BatchNorm2d-191           [-1, 64, 48, 48]             128
          Conv2d-192           [-1, 64, 48, 48]          36,928
            ReLU-193           [-1, 64, 48, 48]               0
     BatchNorm2d-194           [-1, 64, 48, 48]             128
          Conv2d-195          [-1, 128, 48, 48]           8,320
            ReLU-196          [-1, 128, 48, 48]               0
     BatchNorm2d-197          [-1, 128, 48, 48]             256
          Conv2d-198           [-1, 64, 48, 48]           8,256                                                                            [311/1961]
            ReLU-199           [-1, 64, 48, 48]               0
     BatchNorm2d-200           [-1, 64, 48, 48]             128
          Conv2d-201           [-1, 64, 48, 48]          36,928
            ReLU-202           [-1, 64, 48, 48]               0
     BatchNorm2d-203           [-1, 64, 48, 48]             128
          Conv2d-204          [-1, 128, 48, 48]           8,320
            ReLU-205          [-1, 128, 48, 48]               0
     BatchNorm2d-206          [-1, 128, 48, 48]             256
          Conv2d-207           [-1, 64, 48, 48]           8,256
            ReLU-208           [-1, 64, 48, 48]               0
     BatchNorm2d-209           [-1, 64, 48, 48]             128
          Conv2d-210           [-1, 64, 48, 48]          36,928
            ReLU-211           [-1, 64, 48, 48]               0
     BatchNorm2d-212           [-1, 64, 48, 48]             128
          Conv2d-213          [-1, 128, 48, 48]           8,320
            ReLU-214          [-1, 128, 48, 48]               0
       MaxPool2d-215          [-1, 128, 24, 24]               0
     BatchNorm2d-216          [-1, 128, 24, 24]             256
          Conv2d-217          [-1, 256, 24, 24]          33,024
     BatchNorm2d-218          [-1, 256, 24, 24]             512
          Conv2d-219           [-1, 64, 24, 24]          16,448
            ReLU-220           [-1, 64, 24, 24]               0
     BatchNorm2d-221           [-1, 64, 24, 24]             128
          Conv2d-222           [-1, 64, 24, 24]          36,928
            ReLU-223           [-1, 64, 24, 24]               0
     BatchNorm2d-224           [-1, 64, 24, 24]             128
          Conv2d-225          [-1, 256, 24, 24]          16,640
            ReLU-226          [-1, 256, 24, 24]               0
     BatchNorm2d-227          [-1, 256, 24, 24]             512
          Conv2d-228           [-1, 64, 24, 24]          16,448
            ReLU-229           [-1, 64, 24, 24]               0
     BatchNorm2d-230           [-1, 64, 24, 24]             128
          Conv2d-231           [-1, 64, 24, 24]          36,928
            ReLU-232           [-1, 64, 24, 24]               0
     BatchNorm2d-233           [-1, 64, 24, 24]             128
          Conv2d-234          [-1, 256, 24, 24]          16,640                                                                            [275/1961]
            ReLU-235          [-1, 256, 24, 24]               0
     BatchNorm2d-236          [-1, 256, 24, 24]             512
          Conv2d-237           [-1, 64, 24, 24]          16,448
            ReLU-238           [-1, 64, 24, 24]               0
     BatchNorm2d-239           [-1, 64, 24, 24]             128
          Conv2d-240           [-1, 64, 24, 24]          36,928
            ReLU-241           [-1, 64, 24, 24]               0
     BatchNorm2d-242           [-1, 64, 24, 24]             128
          Conv2d-243          [-1, 256, 24, 24]          16,640
            ReLU-244          [-1, 256, 24, 24]               0
     BatchNorm2d-245          [-1, 256, 24, 24]             512
          Conv2d-246           [-1, 64, 24, 24]          16,448
            ReLU-247           [-1, 64, 24, 24]               0
     BatchNorm2d-248           [-1, 64, 24, 24]             128
          Conv2d-249           [-1, 64, 24, 24]          36,928
            ReLU-250           [-1, 64, 24, 24]               0
     BatchNorm2d-251           [-1, 64, 24, 24]             128
          Conv2d-252          [-1, 256, 24, 24]          16,640
            ReLU-253          [-1, 256, 24, 24]               0
       MaxPool2d-254          [-1, 256, 12, 12]               0
     BatchNorm2d-255          [-1, 256, 12, 12]             512
          Conv2d-256          [-1, 384, 12, 12]          98,688
     BatchNorm2d-257          [-1, 384, 12, 12]             768
          Conv2d-258           [-1, 96, 12, 12]          36,960
            ReLU-259           [-1, 96, 12, 12]               0
     BatchNorm2d-260           [-1, 96, 12, 12]             192
          Conv2d-261           [-1, 96, 12, 12]          83,040
            ReLU-262           [-1, 96, 12, 12]               0
     BatchNorm2d-263           [-1, 96, 12, 12]             192
          Conv2d-264          [-1, 384, 12, 12]          37,248
            ReLU-265          [-1, 384, 12, 12]               0
     BatchNorm2d-266          [-1, 384, 12, 12]             768
          Conv2d-267           [-1, 96, 12, 12]          36,960
            ReLU-268           [-1, 96, 12, 12]               0
     BatchNorm2d-269           [-1, 96, 12, 12]             192
          Conv2d-270           [-1, 96, 12, 12]          83,040                                                                            [239/1961]
            ReLU-271           [-1, 96, 12, 12]               0
     BatchNorm2d-272           [-1, 96, 12, 12]             192
          Conv2d-273          [-1, 384, 12, 12]          37,248
            ReLU-274          [-1, 384, 12, 12]               0
     BatchNorm2d-275          [-1, 384, 12, 12]             768
          Conv2d-276           [-1, 96, 12, 12]          36,960
            ReLU-277           [-1, 96, 12, 12]               0
     BatchNorm2d-278           [-1, 96, 12, 12]             192
          Conv2d-279           [-1, 96, 12, 12]          83,040
            ReLU-280           [-1, 96, 12, 12]               0
     BatchNorm2d-281           [-1, 96, 12, 12]             192
          Conv2d-282          [-1, 384, 12, 12]          37,248
            ReLU-283          [-1, 384, 12, 12]               0
     BatchNorm2d-284          [-1, 384, 12, 12]             768
          Conv2d-285           [-1, 96, 12, 12]          36,960
            ReLU-286           [-1, 96, 12, 12]               0
     BatchNorm2d-287           [-1, 96, 12, 12]             192
          Conv2d-288           [-1, 96, 12, 12]          83,040
            ReLU-289           [-1, 96, 12, 12]               0
     BatchNorm2d-290           [-1, 96, 12, 12]             192
          Conv2d-291          [-1, 384, 12, 12]          37,248
            ReLU-292          [-1, 384, 12, 12]               0
       MaxPool2d-293            [-1, 384, 6, 6]               0
     BatchNorm2d-294            [-1, 384, 6, 6]             768
          Conv2d-295            [-1, 512, 6, 6]         197,120
     BatchNorm2d-296            [-1, 512, 6, 6]           1,024
          Conv2d-297            [-1, 128, 6, 6]          65,664
            ReLU-298            [-1, 128, 6, 6]               0
     BatchNorm2d-299            [-1, 128, 6, 6]             256
          Conv2d-300            [-1, 128, 6, 6]         147,584
            ReLU-301            [-1, 128, 6, 6]               0
     BatchNorm2d-302            [-1, 128, 6, 6]             256
          Conv2d-303            [-1, 512, 6, 6]          66,048
            ReLU-304            [-1, 512, 6, 6]               0
     BatchNorm2d-305            [-1, 512, 6, 6]           1,024
          Conv2d-306            [-1, 128, 6, 6]          65,664                                                                            [203/1961]
            ReLU-307            [-1, 128, 6, 6]               0
     BatchNorm2d-308            [-1, 128, 6, 6]             256
          Conv2d-309            [-1, 128, 6, 6]         147,584
            ReLU-310            [-1, 128, 6, 6]               0
     BatchNorm2d-311            [-1, 128, 6, 6]             256
          Conv2d-312            [-1, 512, 6, 6]          66,048
            ReLU-313            [-1, 512, 6, 6]               0
     BatchNorm2d-314            [-1, 512, 6, 6]           1,024
          Conv2d-315            [-1, 128, 6, 6]          65,664
            ReLU-316            [-1, 128, 6, 6]               0
     BatchNorm2d-317            [-1, 128, 6, 6]             256
          Conv2d-318            [-1, 128, 6, 6]         147,584
            ReLU-319            [-1, 128, 6, 6]               0
     BatchNorm2d-320            [-1, 128, 6, 6]             256
          Conv2d-321            [-1, 512, 6, 6]          66,048
            ReLU-322            [-1, 512, 6, 6]               0
     BatchNorm2d-323            [-1, 512, 6, 6]           1,024
          Conv2d-324            [-1, 128, 6, 6]          65,664
            ReLU-325            [-1, 128, 6, 6]               0
     BatchNorm2d-326            [-1, 128, 6, 6]             256
          Conv2d-327            [-1, 128, 6, 6]         147,584
            ReLU-328            [-1, 128, 6, 6]               0
     BatchNorm2d-329            [-1, 128, 6, 6]             256
          Conv2d-330            [-1, 512, 6, 6]          66,048
            ReLU-331            [-1, 512, 6, 6]               0
       MaxPool2d-332            [-1, 512, 1, 1]               0
================================================================
Total params: 5,369,344
Trainable params: 5,369,344
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 746496.00
Forward/backward pass size (MB): 319.93
Params size (MB): 20.48
Estimated Total Size (MB): 746836.41
Train images done                                                                                                                          [166/1961]
Val images done
Epoch: 1 Training_Loss: 0.237755 Val_acc: 0.175305
Train images done
Val images done
Epoch: 2 Training_Loss: 0.212773 Val_acc: 0.173780
Train images done
Val images done
Epoch: 3 Training_Loss: 0.184692 Val_acc: 0.173780
Train images done
Val images done
Epoch: 4 Training_Loss: 0.166755 Val_acc: 0.172256
Train images done
Val images done
Epoch: 5 Training_Loss: 0.156170 Val_acc: 0.173780
Train images done
Val images done
Epoch: 6 Training_Loss: 0.147023 Val_acc: 0.169207
Train images done
Val images done
Epoch: 7 Training_Loss: 0.139578 Val_acc: 0.175305
Train images done
Val images done
Epoch: 8 Training_Loss: 0.134213 Val_acc: 0.175305
Train images done
Val images done
Epoch: 9 Training_Loss: 0.129435 Val_acc: 0.176829
Train images done
Val images done
Epoch: 10 Training_Loss: 0.124475 Val_acc: 0.175305
Train images done
Val images done
Epoch: 11 Training_Loss: 0.121619 Val_acc: 0.173780
Train images done
Val images done
Epoch: 12 Training_Loss: 0.117903 Val_acc: 0.175305
Train images done                                                                                                                          [130/1961]
Val images done
Epoch: 13 Training_Loss: 0.114629 Val_acc: 0.173780
Train images done
Val images done
Epoch: 14 Training_Loss: 0.111813 Val_acc: 0.169207
Train images done
Val images done
Epoch: 15 Training_Loss: 0.108546 Val_acc: 0.167683
Train images done
Val images done
Epoch: 16 Training_Loss: 0.106208 Val_acc: 0.173780
Train images done
Val images done
Epoch: 17 Training_Loss: 0.103470 Val_acc: 0.169207
Train images done
Val images done
Epoch: 18 Training_Loss: 0.101684 Val_acc: 0.172256
Train images done
Val images done
Epoch: 19 Training_Loss: 0.099758 Val_acc: 0.179878
Train images done
Val images done
Epoch: 20 Training_Loss: 0.096763 Val_acc: 0.170732
Train images done
Val images done
Epoch: 21 Training_Loss: 0.095262 Val_acc: 0.175305
Train images done
Val images done
Epoch: 22 Training_Loss: 0.092961 Val_acc: 0.173780
Train images done
Val images done
Epoch: 23 Training_Loss: 0.091694 Val_acc: 0.169207
Train images done
Val images done
Epoch: 24 Training_Loss: 0.089213 Val_acc: 0.178354
Train images done                                                                                                                           [94/1961]
Val images done
Epoch: 25 Training_Loss: 0.086872 Val_acc: 0.178354
Train images done
Val images done
Epoch: 26 Training_Loss: 0.084002 Val_acc: 0.175305
Train images done
Val images done
Epoch: 27 Training_Loss: 0.083467 Val_acc: 0.169207
Train images done
Val images done
Epoch: 28 Training_Loss: 0.081032 Val_acc: 0.172256
Train images done
Val images done
Epoch: 29 Training_Loss: 0.079972 Val_acc: 0.179878
Train images done
Val images done
Epoch: 30 Training_Loss: 0.078064 Val_acc: 0.172256
^[[BTrain images done
Val images done
Epoch: 31 Training_Loss: 0.076063 Val_acc: 0.163110
Train images done
Val images done
Epoch: 32 Training_Loss: 0.075000 Val_acc: 0.170732
Train images done
Val images done
Epoch: 33 Training_Loss: 0.073822 Val_acc: 0.181402
Train images done
Val images done
Epoch: 34 Training_Loss: 0.071288 Val_acc: 0.172256
Train images done
Val images done
Epoch: 35 Training_Loss: 0.068426 Val_acc: 0.178354
Train images done
Val images done
Epoch: 36 Training_Loss: 0.067398 Val_acc: 0.178354
Train images done                                                                                                                           [58/1961]
Val images done
Epoch: 37 Training_Loss: 0.066509 Val_acc: 0.167683
Train images done
Val images done
Epoch: 38 Training_Loss: 0.066503 Val_acc: 0.173780
Train images done
Val images done
Epoch: 39 Training_Loss: 0.063879 Val_acc: 0.169207
Train images done
Val images done
Epoch: 40 Training_Loss: 0.062843 Val_acc: 0.173780
Train images done
Val images done
Epoch: 41 Training_Loss: 0.062297 Val_acc: 0.173780
Train images done
Val images done
Epoch: 42 Training_Loss: 0.059844 Val_acc: 0.163110
Train images done
Val images done
Epoch: 43 Training_Loss: 0.059601 Val_acc: 0.175305
Train images done
Val images done
Epoch: 44 Training_Loss: 0.058575 Val_acc: 0.169207
Train images done
Val images done
Epoch: 45 Training_Loss: 0.057019 Val_acc: 0.176829
Train images done
Val images done
Epoch: 46 Training_Loss: 0.056758 Val_acc: 0.175305
Train images done
Val images done
Epoch: 47 Training_Loss: 0.055101 Val_acc: 0.175305
Train images done
Val images done
Epoch: 48 Training_Loss: 0.053946 Val_acc: 0.173780
Train images done
Val images done
Epoch: 49 Training_Loss: 0.052923 Val_acc: 0.173780
Train images done
Val images done
Epoch: 50 Training_Loss: 0.051680 Val_acc: 0.170732
Train images done
Val images done
Epoch: 51 Training_Loss: 0.050902 Val_acc: 0.167683
Train images done
Val images done
Epoch: 52 Training_Loss: 0.049434 Val_acc: 0.176829
Train images done
Val images done
Epoch: 53 Training_Loss: 0.050003 Val_acc: 0.178354
Train images done
Val images done
Epoch: 54 Training_Loss: 0.048388 Val_acc: 0.167683
